import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
%matplotlib inline
df = pd.read_csv(r'd:\dataset\cardataset\data.csv')
print('numero de linhas:',len(df))
#lowercase todos os nomes de colunas e substitui espaços por _
df.columns = df.columns.str.lower().str.replace(' ', '_')
#seleciona somente colunas com strings
string_columns = list(df.dtypes[df.dtypes =='object'].index)
# Coloca em lowercase e substitui espaço por _ para valores em todas as colunas com string
for col in string_columns: 
    df[col] = df[col].str.lower().str.replace(' ', '_')

#sns.histplot(df.msrp, bins=40) #ocorrências x preço, muita concentração em baixos preços (long tail)
#sns.histplot(df.msrp[df.msrp < 100000]) #seleciona os carros com preço menor que 100k

log_price = np.log1p(df.msrp) # coloca preço em base logaritmica para facilitar a prendizagem do algoritmo, 
#remove o efeito de cauda longa
#sns.histplot(log_price) # gráfico parece um sino

df.isnull().sum() #verificar os dados faltantes
np.random.seed(2) #fixa o seed
n = len(df) #obtem número de linhas
idx = np.arange(n) #cria indices de 0 a n-1
np.random.shuffle(idx) #embaralha os índices
df_shuffled = df.iloc[idx] #cria um dataset embaralhado

#divisão do dataset em treinamento, avaliação e teste
n_val = int(0.2*n)
n_test = int(0.2*n)
n_train = n-(n_val+n_test)

df_train = df_shuffled.iloc[:n_train].copy()
df_val = df_shuffled.iloc[n_train:n_train+n_val].copy()
df_test = df_shuffled.iloc[n_train+n_val:].copy() 
print(len(df_test))

#Aplicar a transformação de log à variavel msrp dos 3 subdatasets
y_train = np.log1p(df_train.msrp.values)
y_val = np.log1p(df_val.msrp.values) 
y_test = np.log1p(df_test.msrp.values)

#remover o campo msrp (preço) para não pegar essa coluna no dataset
del df_train['msrp']
del df_val['msrp']
del df_test['msrp']

#algoritmo de regressão linear
def train_linear_regression(X,y):
    ones = np.ones(X.shape[0]) #cria um array de 1s
    X = np.column_stack([ones, X]) # adiciona o array de 1s a primeira coluna de X
    XTX = X.T.dot(X)
    XTX_inv = np.linalg.inv(XTX) #calcula a inversa
    w = XTX_inv.dot(X.T).dot(y)
    return w[0], w[1:] #retorna os pesos

#seleção dos atributos 
base = ['engine_hp','engine_cylinders','highway_mpg','city_mpg', 'popularity']
#df_num = df_train[base] #dataset de treino com os atributos selecionados
#df_num = df_num.fillna(0) #preenche os campos vazios com zero

def prepare_X(df):
    df = df.copy() # cria uma copia de base
    features = base.copy() # cria uma copia da lista base com as características básicas
    df['age'] = 2017 - df.year
    features.append('age')
    
    for v in [2,3,4]:
        feature = 'num_doors_%s' % v
        df[feature] = (df['number_of_doors'] == v).astype(int)
        features.append(feature)
    
    for v in ['chevrolet','ford','volkswagen','toyota','dodge']:
        feature = 'is_make_%s' % v
        df[feature]=(df['make'] ==v).astype(int)
        features.append(feature)
        
    for v in ['regular_unleaded','premium_unleaded_(required)','premium_unleaded_(recommended)','flex-fuel_(unleaded/e85)']:
        feature = 'is_type_%s' % v
        df[feature]=(df['engine_fuel_type'] ==v).astype(int)
        features.append(feature)
    
    for v in ['automatic','manual','automated_manual']:
        feature = 'is_transmission_%s' % v
        df[feature]=(df['transmission_type'] ==v).astype(int)
        features.append(feature)
    
    for v in ['front_wheel_drive','rear_wheel_drive','all_wheel_drive','four_wheel_drive']:
        feature = 'is_driven_wheels_%s' % v
        df[feature]=(df['driven_wheels'] ==v).astype(int)
        features.append(feature)
    
    for v in ['crossover','flex_fuel','luxury','luxury,performance','hatchback']:
        feature = 'is_mc_%s' % v
        df[feature]=(df['market_category'] ==v).astype(int)
        features.append(feature)
    
    for v in ['compact','midsize','large']:
        feature = 'is_size_%s' % v
        df[feature]=(df['vehicle_size'] ==v).astype(int)
        features.append(feature)
        
    for v in ['sedan','4dr_suv','coupe', 'convertible', '4dr_hatchback']:
        feature = 'is_style_%s' % v
        df[feature]=(df['vehicle_style'] ==v).astype(int)
        features.append(feature)
    
    
    df_num = df[features]
    df_num = df_num.fillna(0)
    X = df_num.values
    return X

def rmse(y, y_pred):
    error =y_pred -y
    mse = (error **2).mean()
    return np.sqrt(mse)

X_train = prepare_X(df_train)
w_0, w = train_linear_regression(X_train, y_train)
X_val = prepare_X(df_val)
y_pred = w_0 + X_val.dot(w)
print ('Calculo do erro de validacao com a caracter. age: ', rmse(y_val, y_pred))


def train_linear_regression_reg(X,y, r=0.0):
    ones = np.ones(X.shape[0]) #cria um array de 1s
    X = np.column_stack([ones,X]) #adiciona o array de 1s a primeira coluna de X
    
    XTX = X.T.dot(X) 
    
    reg = r * np.eye(XTX.shape[0]) #adiciona regularização para evitar que w cresca sem limites
    XTX = XTX+reg
    
    XTX_inv = np.linalg.inv(XTX)
    w= XTX_inv.dot(X.T).dot(y)
    return w[0], w[1:] #retorna os pesos

#Teste para valores diferentes de r
print('Teste de valores de r:')
for r in [0.000001, 0.0001, 0.001, 0.01, 1, 5, 10]:
    w_0, w=train_linear_regression_reg(X_train, y_train, r=r)
    y_pred = w_0 + X_val.dot(w)
    print('%6s' %r, rmse(y_val, y_pred))

    #após a simulação r=0.01 é uma boa solução 

X_train = prepare_X(df_train) #obtem o w_0 e w do modelo (test)
w_0, w=train_linear_regression_reg(X_train, y_train, r = 0.001)

X_val = prepare_X(df_val)
y_pred = w_0 + X_val.dot(w) # usa w_0 e w do modelo (test)
print("validação:", rmse(y_val, y_pred))

# Testando com o dataset de test: 
X_test = prepare_X(df_test)
y_pred = w_0 + X_test.dot(w)
print('test:', rmse(y_test, y_pred))
#Como os valores de rmse de validation e test são próximos, nós podemos 
#generalizar bem para novos dados não usados. 

#Usando o modelo. 
#Supondo um post de usuario como as seguintes caracteristicas
ad = {
    'city_mpg': 18, 
    'driven_wheels': 'all_wheel_drive',
    'engine_cylinders': 6.0, 
    'engine_fuel_type': 'regular_unleaded',
    'engine_hp': 268.0,
    'highway_mpg': 25, 
    'make': 'toyota',
    'market_category': 'crossover,performance',
    'model':'venza',
    'number_of_doors': 4.0, 
    'popularity': 2031, 
    'transmission_type': 'automatic',
    'vehicle_size': 'midsize',
    'vehicle_style':'wagon',
    'year':2013
}

df_test = pd.DataFrame([ad])
X_test = prepare_X(df_test)
y_pred = w_0 + X_test.dot(w)

#como foi utilizado o logaritmo, tem que usar o processo contrário: 
suggestion = np.expm1(y_pred)
print('valor:', suggestion)

#Conclusão: a saída para o teste resultou em 28 294,13 e o preço real 
#do carro é de 31 120, 00, ou seja, a predição do valor não está longe
#do valor real. 
